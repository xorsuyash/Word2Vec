{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K9hU4JIXG7wc"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "fG780eGsHLYB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "AUTOTUNE =tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "77wC6mDUHZX3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The wide road shimmered in the hot sun\"\n",
        "tokens =  list(sentence.lower().split())\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFEhMWZoHfou",
        "outputId": "3252d423-c337-4f80-bb68-4fdf9efc7cd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEyhrgqlHw1p",
        "outputId": "f7dbf353-f0cb-4e13-c2c7-57e8af7ea5cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'wide', 'road', 'shimmered', 'in', 'the', 'hot', 'sun']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab,index={},1\n",
        "vocab['<pad>'] = 0\n",
        "for token in tokens:\n",
        "  if token not in vocab:\n",
        "    vocab[token]=index\n",
        "    index+=1\n",
        "vocab_size=len(vocab)\n",
        "print(vocab )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH8OFh0mHyAA",
        "outputId": "3e1f13ca-e54a-4779-b5cd-0343264deb72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab={idx: token for token,idx in vocab.items()}\n",
        "print(inverse_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jKxEkoGISO9",
        "outputId": "9c9eec22-c49a-4efb-8fd7-b4b0851c8946"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sequence = [vocab[word] for word in tokens]\n",
        "print(example_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X75XTZGNIi3z",
        "outputId": "7337c98e-a882-47e0-bf7b-1746018cd4c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 1, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size=2\n",
        "positive_skip_grams,_=tf.keras.preprocessing.sequence.skipgrams(example_sequence,vocabulary_size=vocab_size,window_size=window_size,negative_samples=0)"
      ],
      "metadata": {
        "id": "f3kVa0njIrxt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams=[]\n",
        "for i in range(len(positive_skip_grams)):\n",
        "  context=inverse_vocab[positive_skip_grams[i][0]]\n",
        "  target=inverse_vocab[positive_skip_grams[i][1]]\n",
        "  skip_grams.append((context,target))"
      ],
      "metadata": {
        "id": "4gZYvWECJYET"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDBA3YpDJdXq",
        "outputId": "e749438b-d9fe-482e-b55e-6a1901e7f554"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('road', 'in'),\n",
              " ('wide', 'shimmered'),\n",
              " ('shimmered', 'the'),\n",
              " ('road', 'wide'),\n",
              " ('shimmered', 'in'),\n",
              " ('sun', 'the'),\n",
              " ('wide', 'the'),\n",
              " ('in', 'shimmered'),\n",
              " ('the', 'hot'),\n",
              " ('road', 'the'),\n",
              " ('the', 'road'),\n",
              " ('in', 'the'),\n",
              " ('the', 'shimmered'),\n",
              " ('in', 'hot'),\n",
              " ('shimmered', 'wide'),\n",
              " ('hot', 'sun'),\n",
              " ('wide', 'road'),\n",
              " ('the', 'in'),\n",
              " ('the', 'sun'),\n",
              " ('hot', 'the'),\n",
              " ('hot', 'in'),\n",
              " ('sun', 'hot'),\n",
              " ('road', 'shimmered'),\n",
              " ('in', 'road'),\n",
              " ('shimmered', 'road'),\n",
              " ('the', 'wide')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ggweUNTKyWW",
        "outputId": "7aff54eb-4ba4-4704-aea1-1450bb31c896"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The wide road shimmered in the hot sun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#negative sampling for skipgram"
      ],
      "metadata": {
        "id": "Z16EsnTrK392"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_word,context_word = positive_skip_grams[0]\n",
        "\n",
        "num_ns=4\n",
        "\n",
        "context_class =tf.reshape(tf.constant(context_word,dtype=\"int64\"),(1,1))"
      ],
      "metadata": {
        "id": "vjTSdsc5LDmP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_class\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJIU933kMqql",
        "outputId": "4322cea9-51e9-477a-8f82-f2ed1d5d031a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_sampling_candidates,_,_=tf.random.log_uniform_candidate_sampler(true_classes=context_class,num_true=1,num_sampled=num_ns,unique=True,range_max=vocab_size,seed=SEED,name=\"negative_Sampling\")"
      ],
      "metadata": {
        "id": "SFd4YXYHMsp7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(negative_sampling_candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5mzFAqwNmkM",
        "outputId": "6e35066a-c098-472a-bc25-5e38d1033905"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in negative_sampling_candidates:\n",
        "  print(inverse_vocab[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_jPAC9oNpcy",
        "outputId": "a753d84d-c785-43fc-9c29-822e9c43afd1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wide\n",
            "the\n",
            "shimmered\n",
            "road\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inverse_vocab[context_word])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucTmJ-8zN6mY",
        "outputId": "ebbaafb3-0469-45cb-f59c-25e47b34d471"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_context_class = tf.squeeze(context_class,1)"
      ],
      "metadata": {
        "id": "7e2kDgiZOjrS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_context_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PGjwnmqO-pH",
        "outputId": "e0ad4b8d-7d12-43c9-ad55-e276128e5bd8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([5])>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context=tf.concat([squeezed_context_class,negative_sampling_candidates],0)"
      ],
      "metadata": {
        "id": "L_Hc_8sqPDoB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8fO5v3VPTe_",
        "outputId": "4c055403-9d14-48f3-bd5f-5e6e0e6f8e5c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([5, 2, 1, 4, 3])>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=tf.constant([1]+[0]*num_ns,dtype=\"int64\")"
      ],
      "metadata": {
        "id": "hG8LwKDcPV3p"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPmzrIZXPp97",
        "outputId": "c80df511-19f2-454d-d622-c87afa8ccc7f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 0, 0, 0, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target=target_word"
      ],
      "metadata": {
        "id": "nqKdhmqAP2i1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOoEnTvwP8Z_",
        "outputId": "710ade7a-facd-4a53-a441-36512078d99d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"target_index    : {target}\")\n",
        "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
        "print(f\"context_indices : {context}\")\n",
        "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
        "print(f\"label           : {labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bemHUtBcQAOh",
        "outputId": "53649041-a71d-4c0c-ab61-c7f2a9a10bb9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target_index    : 3\n",
            "target_word     : road\n",
            "context_indices : [5 2 1 4 3]\n",
            "context_words   : ['in', 'wide', 'the', 'shimmered', 'road']\n",
            "label           : [1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"target  :\", target)\n",
        "print(\"context :\", context)\n",
        "print(\"label   :\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfueYomWQOu0",
        "outputId": "7a15ee4c-9b73-4249-d9f0-b812abbc25fb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target  : 3\n",
            "context : tf.Tensor([5 2 1 4 3], shape=(5,), dtype=int64)\n",
            "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_table=tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
        "print(sampling_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aUKE_SEQV_I",
        "outputId": "35b1ae8e-6110-461c-d8b7-83892fdd920e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
            " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for `vocab_size` tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in the dataset.\n",
        "  for sequence in tqdm.tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples\n",
        "    # with a positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1,\n",
        "          num_sampled=num_ns,\n",
        "          unique=True,\n",
        "          range_max=vocab_size,\n",
        "          seed=seed,\n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels\n",
        ""
      ],
      "metadata": {
        "id": "-pQPSudUTpRO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsnRRof9dbiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWn2LsGfX-qH",
        "outputId": "da63423d-51bb-449e-988b-d1aa74eebb18"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_file) as f:\n",
        "  lines=f.read().splitlines()\n",
        "\n",
        "\n",
        "for line in lines[:20]:\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJhoN25LY53q",
        "outputId": "4675b555-8832-4858-8f97-4e1940d940c3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_ds=tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x),bool))"
      ],
      "metadata": {
        "id": "jAcKmNIhZQCU"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBqkIE-YZngy",
        "outputId": "ab21c2d8-0a24-4203-e6fc-c3b7b9832fb6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_FilterDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=4096\n",
        "sequence_length = 10\n",
        "vectorize_layer=layers.TextVectorization(standardize=coustom_standarization,max_tokens=vocab_size,output_mode='int',output_sequence_length=sequence_length)"
      ],
      "metadata": {
        "id": "xsf9DD2SaYpz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coustom_standarization(input_data):\n",
        "   lowercase = tf.strings.lower(input_data)\n",
        "   return tf.strings.regex_replace(lowercase,'[%s]'% re.escape(string.punctuation),'')"
      ],
      "metadata": {
        "id": "6GmA6xBQZpnu"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ],
      "metadata": {
        "id": "gkeVWQeGa9l5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab=vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "lOlv1mpFbVFC"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inverse_vocab[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sucsHRotb0GQ",
        "outputId": "bf8a146d-323e-4f47-cfe0-3db2af2a4b1f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'and',\n",
              " 'to',\n",
              " 'i',\n",
              " 'of',\n",
              " 'you',\n",
              " 'my',\n",
              " 'a',\n",
              " 'that',\n",
              " 'in',\n",
              " 'is',\n",
              " 'not',\n",
              " 'for',\n",
              " 'with',\n",
              " 'me',\n",
              " 'it',\n",
              " 'be',\n",
              " 'your',\n",
              " 'his',\n",
              " 'this',\n",
              " 'but',\n",
              " 'he',\n",
              " 'have',\n",
              " 'as',\n",
              " 'thou',\n",
              " 'him',\n",
              " 'so',\n",
              " 'what',\n",
              " 'thy',\n",
              " 'will',\n",
              " 'no',\n",
              " 'by',\n",
              " 'all',\n",
              " 'king',\n",
              " 'we',\n",
              " 'shall',\n",
              " 'her',\n",
              " 'if',\n",
              " 'our',\n",
              " 'are',\n",
              " 'do',\n",
              " 'thee',\n",
              " 'now',\n",
              " 'lord',\n",
              " 'good',\n",
              " 'on',\n",
              " 'o',\n",
              " 'come',\n",
              " 'from',\n",
              " 'sir',\n",
              " 'or',\n",
              " 'which',\n",
              " 'more',\n",
              " 'then',\n",
              " 'well',\n",
              " 'at',\n",
              " 'would',\n",
              " 'was',\n",
              " 'they',\n",
              " 'how',\n",
              " 'here',\n",
              " 'she',\n",
              " 'than',\n",
              " 'their',\n",
              " 'them',\n",
              " 'ill',\n",
              " 'duke',\n",
              " 'am',\n",
              " 'hath',\n",
              " 'say',\n",
              " 'let',\n",
              " 'when',\n",
              " 'one',\n",
              " 'go',\n",
              " 'were',\n",
              " 'love',\n",
              " 'may',\n",
              " 'us',\n",
              " 'make',\n",
              " 'upon',\n",
              " 'yet',\n",
              " 'richard',\n",
              " 'like',\n",
              " 'there',\n",
              " 'must',\n",
              " 'should',\n",
              " 'an',\n",
              " 'first',\n",
              " 'why',\n",
              " 'queen',\n",
              " 'had',\n",
              " 'know',\n",
              " 'man',\n",
              " 'did',\n",
              " 'tis',\n",
              " 'where',\n",
              " 'see',\n",
              " 'some']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
      ],
      "metadata": {
        "id": "faMreBpkb7JY"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list(text_vector_ds.as_numpy_iterator())\n",
        "print(len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyHJxvRQciEf",
        "outputId": "8835f757-95f0-4726-a424-e6aa904e4120"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences[:5]:\n",
        "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST2z1LAtdAZA",
        "outputId": "56e31783-2599-4ada-b513-d6d59d4831b2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
            "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
            "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
            "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
            "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences,\n",
        "    window_size=2,\n",
        "    num_ns=4,\n",
        "    vocab_size=vocab_size,\n",
        "    seed=SEED)\n",
        "\n",
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTpcbss3dEvf",
        "outputId": "3f7b2f41-dff1-4357-f507-7971595cf8ca"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32777/32777 [00:25<00:00, 1278.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "targets.shape: (64730,)\n",
            "contexts.shape: (64730, 5)\n",
            "labels.shape: (64730, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7-W9zFLeXwO",
        "outputId": "86f96e05-78a5-4813-d944-8ace1518e09d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3690, 3690, 1286, ...,  129,  129, 1049])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-C4BFt4ekgI",
        "outputId": "31907c35-8f8d-4673-eca1-f483b7242fb8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   4,  170,   19,  826,   57],\n",
              "       [  64,    1,   20,   84,   11],\n",
              "       [1286,  280, 1633,    3,    9],\n",
              "       ...,\n",
              "       [  26,   94,    9,   10,    0],\n",
              "       [1874,  112,    2,   32,  655],\n",
              "       [  26,   12,  133, 2260, 4059]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUwIuQ9UentY",
        "outputId": "7ebd4756-dae6-4c59-80a8-e84b8940493b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoN_Oq-zfCHx",
        "outputId": "6e2e303b-c065-4793-db28-dcfe4b6f3f68"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,vocab_size,embedding_dim):\n",
        "    super(Word2Vec,self).__init__()\n",
        "    self.target_embedding = layers.Embedding(vocab_size,embedding_dim,\n",
        "                                             input_length=1,\n",
        "                                             name=\"w2v_embedding\")\n",
        "    self.context_embedding=layers.Embedding(vocab_size,embedding_dim,input_length=num_ns+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self,pair):\n",
        "    target,context=pair\n",
        "\n",
        "    if len(target.shape)==2:\n",
        "      target = tf.squeeze(target,axis=1)\n",
        "\n",
        "    word_emb=self.target_embedding(target)\n",
        "\n",
        "    context_emb=self.context_emb(context)\n",
        "\n",
        "    dots = tf.einsum('be,bce->bc',word_emb,context_emb)\n",
        "    return dots\n"
      ],
      "metadata": {
        "id": "aEw-FRjHfILg"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def custom_loss(x_logit, y_true):\n",
        "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
      ],
      "metadata": {
        "id": "rT0b5ZsdhDBA"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WTMzIJqVhJKm"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ],
      "metadata": {
        "id": "wVgqiMtAhVRc"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word2Vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "OJqZI_4thY8s",
        "outputId": "c536ab4b-8eea-4c10-fd93-0508f74642fc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-b210d30e5654>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute '_assert_compile_was_called'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WrS7PYrAhbkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}